---
title: "Exercise: censored observations"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise instructions

This is the same exercise as 2.1 except that now the mode and the inference are performed with MCMC using Stan. Hence, instead of the grid based approximation we use Monte Carlo approximation to do the same analyses as in exercise 2.1.

Suppose you have a $Beta(1,1)$ prior distribution on the probability $\theta$ 
that a coin will yield a head when spun in a specified manner. The coin is 
independently spun ten times, and 'heads' appear fewer than 3 times. 
You are not told how many heads were seen, only that the number is 
less than 3. 

\begin{itemize}
  \item[1)] Implement the model with Stan and sample from the posterior of $\theta$.
    \begin{itemize}
      \item[a)] Check for convergence visually and by calculating the PSRF statistics.
      \item[a)] Calculate the autocorrelation of the samples.
    \end{itemize}
  \item[2)] Using the samples of $\theta$ 
    \begin{itemize}
      \item[a)] draw the posterior density function of $\theta$ and 
      \item[b)] calculate the posterior probability that $\theta<0.3$ and the 5\% and the 95\% quantiles.
      \item[c)] calculate the posterior mean and variance of $\theta$.
    \end{itemize}
  \item[3)] Draw samples from the posterior predictive distribution for new $\tilde{y}$ in a new sample of size $n=10$ and 
    \begin{itemize}
      \item[a)] draw histogram of samples from the posterior predictive distribution for $\tilde{y}$
      \item[a)] Calculate the posterior predictive mean and variance of $\tilde{y}$
    \end{itemize}
\end{itemize}

## Model answer and grading

The posterior density function in case of censored observation is 

$p(\theta|y<3,n=10) \propto \left(\text{Bin}(0|\theta,n)+\text{Bin}(1|\theta,n)+\text{Bin}(2|\theta,n)\right)\text{Beta}(\theta|1,1)$

When using Stan, we need to first load the needed libraries into R and define a Stan model

```{r}
library(ggplot2)
library(StanHeaders)
library(rstan)
library(coda)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```
# Ex 1
```{r}
censored_observations_model="
//  Fill in here the model. See mark-recapture example and Stan manual for help
data {
  int<lower = 0> N;
  int<lower = 0> y;
}
parameters {
  real<lower = 0> theta;
}
model {
  theta ~ beta(1, 1);
  for (i in 0:y-1) {
    target += binomial_lpmf(i|N, theta);
  }
}
"
```

Next, define the data list and run Markov chain with Stan

```{r}
N <- 10
y <- 3
dataset <- list ('N'=N, 'y'=y) 

#give initial values for all chains for parameter N
init1 <- list(N=10)
init2 <- list(N=100)
init3 <- list(N=400)
inits <- list(init1, init2, init3) 

#stan function does all of the work of fitting a Stan model and returning the results as an instance 
#of stanfit = post in our exercises.
post=stan(model_code=censored_observations_model,data=dataset,init=inits,warmup=500,iter=2000,chains=3,thin=1)
```


Next we can examine the posterior samples in various ways. See mark-recapture example for help

```{r}
# visual inspection 
plot(post, plotfun='trace', pars='theta', inc_warmup=T)

# Inspection with PSRF=Rhat
print(post, pars='theta')

# Compared summary statistics for different chains
summary(post, pars='theta')

#Calculate the autocorrelation of the samples after removing burn-in.  Is autocorrelation a problem here?
# - Autocorrelation does not seem to be a problem as the values are really close to zero or even negative
stan_ac(post, 'theta', inc_warmup=F, lags=25)

#plot histogram of the posterior of theta (approximation for density function)
plot(post, plotfun='hist', pars='theta', bins=50)

# calculate the probability that theta<0.3 and 5% and 95% quantiles
post_summary <- summary(post, pars='theta', probs=c(0.3, 0.05, 0.95))
post_summary$summary
sprintf('Posterior probability that theta < 0.3: %f', post_summary$summary[4])
sprintf('Posterior probability 5pct quatile: %f', post_summary$summary[5])
sprintf('Posterior probability 95pct quatile: %f', post_summary$summary[6])

#calculate the posterior mean and variance
sprintf('Posterior mean: %f', post_summary$summary[1])
sprintf('Posterior variance: %f', post_summary$summary[3]^2)
```

Next we draw samples from the posterior predictive distribution for new $y$ in a new sample of size $n=10$.

```{r}
n <- 10
samples <- extract(post, pars='theta')
data <- samples$theta[1:10]
hist(data)
sprintf('Posterior sample mean: %f', mean(data))
sprintf('Posterior sample variance: %f', var(data))
```




## Grading

4 points for correclty doing step 1. 3 points for correctly doing step 2. 3 points for correctly doing step 3. 
